# -*- coding: utf-8 -*-
"""Final_Block.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nyu2U5NQf4NuExs8Op1lIDdzrT-FdUhX

# Задание

Дан файл HR.csv с данными по опросу уровня удовлетворенности сотрудниками работой.  
Файл доступен тут -
https://drive.google.com/file/d/1INgo03nal-vwFJe7Lec5vOUtOwfJdUr1/view?usp=sharing

Признаки:
1. satisfaction_level - Уровень удовлетворенности работой
2. Last_evaluation - Время с момента последней оценки в годах
3. number_projects - Количество проектов, выполненных за время работы
4. average_monthly_hours - Среднее количество часов на рабочем месте в месяц
5. time_spend_company - Стаж работы в компании в годах
6. work_accident - Происходили ли несчастные случаи на рабочем месте с сотрудником
7. left - уволился ли сотрудник
8. promotion_last_5years - повышался ли сотрудник за последние пять лет
9. department - отдел в котором работает сотрудник
10. salary - относительный уровень зарплаты

Требуется выполнить следующее задание:
Задания
1. Загрузите файл HR.csv в pandas dataframe
2. Рассчитайте основные статистики для переменных
(среднее,медиана,мода,мин/макс,сред.отклонение).
3. Рассчитайте и визуализировать корреляционную матрицу для
количественных переменных.  
Определите две самые скоррелированные и две наименее
скоррелированные переменные.
4. Рассчитайте сколько сотрудников работает в каждом
департаменте.
5. Показать распределение сотрудников по зарплатам.
6. Показать распределение сотрудников по зарплатам в каждом
департаменте по отдельности.
7. Проверить гипотезу, что сотрудники с высоким окладом
проводят на работе больше времени, чем сотрудники с низким
окладом.
8. Рассчитать следующие показатели среди уволившихся и не
уволившихся сотрудников (по отдельности):
- Доля сотрудников с повышением за последние 5 лет
- Средняя степень удовлетворенности
- Среднее количество проектов
9. Разделить данные на тестовую и обучающую выборки
Построить модель LDA, предсказывающую уволился ли
сотрудник на основе имеющихся факторов (кроме department и
salary)  
Оценить качество модели на тестовой выборки
10. Загрузить jupyter notebook с решение на github и прислать ссылку

Итого - максимум 85 баллов  
Для зачета необходимо набрать минимум 55

# Решение

## 1. Загрузите файл HR.csv в pandas dataframe
"""

# Импорт библиотек
import pandas as pd
# Загрузка файла как DF
hr_df = pd.read_csv('HR.csv')
hr_df.head(5)

hr_df.info()
# пропусков нет, типы данных приемлимые

"""## 2. Рассчитайте основные статистики для переменных (среднее,медиана,мода,мин/макс,сред.отклонение)."""

# Выведем основные статистики (часть данных нехватает)
hr_df.describe()

# напишем свою функцию
pd.options.mode.chained_assignment = None
from pandas.api.types import is_string_dtype
from pandas.api.types import is_numeric_dtype
def stats(data):
    '''Функция принимает DataFrame (data) и рассчитывает базовые статистики и
    возвращает DataFrame для каждого столбца data:
      * min - минимальное значение
      * max - максимальное значение
      * range - размах
      * mean - среднее
      * mode - мода
      * median - медианное значение
      * disp - размах
      * std - стпандартное отклонение
      * q1 - первый квартиль
      * q2 - второй квартиль
      * q3 - третий квартиль
      * unique - список уникальных значений
      * value_counts - частотный анализ данных
    '''
    dfr = pd.DataFrame()
    dfr = pd.DataFrame(data, index =['min', 'max', 'range','mean','mode','median','disp','std','q1','q2','q3','unique','value_counts'])
    for series in data:
      if is_numeric_dtype(dfr[series]):
        dfr[series].loc['min'] = data[series].min()
        dfr[series].loc['max'] = data[series].max()
        dfr[series].loc['range'] = data[series].max() - data[series].min()
        dfr[series].loc['mean'] = data[series].mean()
        dfr[series].loc['mode'] = data[series].mode()[0]
        dfr[series].loc['median'] = data[series].median()
        dfr[series].loc['disp'] = data[series].var()
        dfr[series].loc['std'] = data[series].std()
        dfr[series].loc['q1'] = data[series].quantile(q=1/4)
        dfr[series].loc['q2'] = data[series].quantile(q=1/2)
        dfr[series].loc['q3'] = data[series].quantile(q=3/4)
        dfr[series].loc['q3'] = data[series].quantile(q=3/4)
      elif is_string_dtype(dfr[series]):
        dfr[series].loc['mode'] = data[series].mode()[0]
        dfr[series].loc['value_counts'] = data[series].reset_index().values.tolist()
        dfr[series].loc['unique'] = data[series].unique()


    return dfr

hr_df_stats = stats(hr_df)
hr_df_stats

"""## Рассчитайте и визуализировать корреляционную матрицу для количественных переменных. Определите две самые скоррелированные и две наименее скоррелированные переменные."""

# и визулизируем через тепловую карту
import seaborn as sns
sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.heatmap(hr_df.corr(), annot=True)

# соберём данные и отсортируем их в порядке убывания
cor_table = hr_df.corr().abs()
unst = cor_table.unstack()
sorted_cor_table = unst.sort_values(kind="quicksort", ascending=False)

print(sorted_cor_table.head(50))
# максимальная коррелиция наблюдается между столбцами [number_project - average_montly_hours] и [average_montly_hours - number_project]
# минимальная коррелиция наблюдается между столбцами [Work_accident - average_montly_hours]

"""## 4. Рассчитайте сколько сотрудников работает в каждом департаменте."""

df_hr_departmen_counts = hr_df.groupby(['department']).size().reset_index()
df_hr_departmen_counts.columns = ['department', 'Number_of_employees']
df_hr_departmen_counts

"""## 5. Показать распределение сотрудников по зарплатам."""

hr_df_by_salary = hr_df.groupby('salary')['salary'].count()
hr_df_by_salary

bp = hr_df_by_salary.plot(kind='bar', title = 'Number of employees by salary level', xlabel="salary level", ylabel="Number of employees", figsize = (10,6), cmap='Dark2', rot = 30);
bp.bar_label (bp.containers [ 0 ])

"""## 6. Показать распределение сотрудников по зарплатам в каждом департаменте по отдельности."""

hr_df_salary_by_department = hr_df.groupby([hr_df['department'],hr_df['salary']])[['salary']].count().unstack()
hr_df_salary_by_department

bp = hr_df_salary_by_department.plot(kind='bar', title = 'Number of employees by salary level by department', xlabel="department, salary level", ylabel="Number of employees", figsize = (10,6), cmap='Dark2', rot = 90);
# bp.bar_label (bp.containers [ 0 ]);

"""## 7. Проверить гипотезу, что сотрудники с высоким окладом проводят на работе больше времени, чем сотрудники с низким окладом."""

df_high = list(hr_df.loc[hr_df['salary'] == 'high']['average_montly_hours'])
df_low = list(hr_df.loc[hr_df['salary'] == 'low']['average_montly_hours'])

import matplotlib.pyplot as plt
from statistics import mean


binss = 25
plt.hist(df_high, bins=binss, density=True, rwidth= .8, edgecolor='black', color='blue', label='high level', alpha=1);
plt.hist(df_low, bins=binss, density=True, rwidth= .8, edgecolor='black', color='green', label='low level', alpha=0.9);

plt.axvline(mean(df_high), color='black', linestyle='dashed', linewidth=2, label='Hight Level Mean')
plt.axvline(mean(df_low), color='red', linestyle='dashed', linewidth=2, label='Low Level Mean')

plt.legend(loc='upper right')

plt.title('Density of People by average_montly_hours')
plt.xlabel('average_montly_hours')
plt.ylabel('Density of People')

plt.tight_layout()
plt.show()
#на первый взгляд разница если и есть, то незначительная

from scipy import stats

def h0_mean(data1, data2, alpha = 0.05):
  # H0 - среднее значение двух выборок существенно отличаются
  # H1 - среднее значение двух выборок приблизительно равны
  stat_value, p_value = stats.ttest_ind(data1, data2)
  print(f"Статистика = {stat_value:.5f}, p = {p_value:.5f}")
  if p_value < alpha:
    print("Отклоняем нулевую гипотезу. Можем предположить, что различие между выборками (их средними) незначительно.")
  else:
    print("Принимаем нулевую гипотезу. Предполагаем, что различие между выборками (их средними) незначительно.")

h0_mean(df_high, df_low, 0.001)
# Вывод - различие по уровню зарплат в зависимости от времени работы отсутствует

"""## 8. Рассчитать следующие показатели среди уволившихся и не уволившихся сотрудников (по отдельности):
- Доля сотрудников с повышением за последние 5 лет
- Средняя степень удовлетворенности
- Среднее количество проектов
"""

df_left = hr_df.loc[hr_df['left'] == 1]
df_left_promotion_last_5years = len(df_left.loc[df_left['promotion_last_5years'] == 1])/len(df_left)
df_left_satisfaction_level = df_left['satisfaction_level'].mean()
df_left_number_project = df_left['number_project'].mean()

df_not_left = hr_df.loc[hr_df['left'] == 0]
df_not_left_promotion_last_5years = len(df_not_left.loc[df_not_left['promotion_last_5years'] == 1])/len(df_not_left)
df_not_left_satisfaction_level = df_not_left['satisfaction_level'].mean()
df_not_left_number_project = df_not_left['number_project'].mean()


print(f'Показатели среди уволившихся сотрудников \n- Доля сотрудников с повышением за последние 5 лет: {df_left_promotion_last_5years} \n- Средняя степень удовлетворенности: {df_left_satisfaction_level} \n- Среднее количество проектов: {df_left_number_project}')

print(f'Показатели среди не уволившихся сотрудников \n- Доля сотрудников с повышением за последние 5 лет: {df_not_left_promotion_last_5years} \n- Средняя степень удовлетворенности: {df_not_left_satisfaction_level} \n- Среднее количество проектов: {df_not_left_number_project}')

"""## 9. Регрессия
- Разделить данные на тестовую и обучающую выборки
- Построить модель LDA, предсказывающую уволился ли сотрудник на основе имеющихся факторов (кроме department и salary)
- Оценить качество модели на тестовой выборки
"""

import statsmodels.api as sm
from sklearn.model_selection import train_test_split

# обозначим параметры по осям
X = hr_df[['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','left','promotion_last_5years']]
y = pd.array(hr_df['left'])

# разобьём данные на данные для построения регрессионной модели и тестовые данные в пропорции 0.7 к 0.3
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)
X_const = sm.add_constant(X_train) # техническая особенность библиотеки

# построим модель (обучим) и выведем данные
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)

result = pd.DataFrame([y_test, lda.predict(X_test)]).T
result

from sklearn.metrics import accuracy_score
print(f'Точность предсказательной модели: {accuracy_score(y_test, lda.predict(X_test))}')
# показано высокое качество предсказательной модели

"""## 10. Загрузить jupyter notebook с решение на github и прислать ссылку"""